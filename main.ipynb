{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def clean(img_dir, save_dir, img_name):\n",
    "    # read image\n",
    "    img = cv2.imread(join(img_dir, img_name))\n",
    "\n",
    "    # convert to LAB and extract L  channel\n",
    "    LAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    L = LAB[:,:,0]\n",
    "\n",
    "    # threshold L channel with triangle method\n",
    "    value, thresh = cv2.threshold(L, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_TRIANGLE)\n",
    "    # print(value)\n",
    "\n",
    "    value = value + 10\n",
    "    thresh = cv2.threshold(L, value, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # invert threshold and make 3 channels\n",
    "    thresh = 255 - thresh\n",
    "    mask = cv2.merge([thresh, thresh, thresh])\n",
    "\n",
    "    mask = cv2.blur(mask, (100, 100), 0)\n",
    "\n",
    "    a = 0.83\n",
    "    res = cv2.addWeighted(img, a,mask,1 - a,0)\n",
    "    cv2.imwrite(join(save_dir, img_name), res)\n",
    "    # cv2.imwrite(\"clear_data/photo/out3.jpg\", res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "t = 10\n",
    "# for f in listdir(\"dataset/photo\"):\n",
    "    # clean(\"dataset\\photo\", \"clear_data\\photo\", f)\n",
    "    # t -= 1\n",
    "    # if not t:\n",
    "    #     break\n",
    "\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "path = \"clear_data/photo\"\n",
    "first = listdir(path)[0]\n",
    "second = listdir(path)[1]\n",
    "img1 = cv2.imread(join(path, first), cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(join(path, second), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# cv2.imshow(\"img1\", img1)\n",
    "# cv2.imshow(\"img2\", img2)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# Create our ORB detector and detect keypoints and descriptors\n",
    "orb = cv2.ORB_create(nfeatures=2000)\n",
    "\n",
    "# Find the key points and descriptors with ORB\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(img2, None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# cv2.imshow(\"Key_points1\", cv2.drawKeypoints(img1, keypoints1, None, (255, 0, 255)))\n",
    "# cv2.imshow(\"Key_points2\", cv2.drawKeypoints(img2, keypoints2, None, (255, 0, 255)))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# Create a BFMatcher object.\n",
    "# It will find all of the matching keypoints on two images\n",
    "bf = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "\n",
    "# Find matching points\n",
    "matches = bf.knnMatch(descriptors1, descriptors2,k=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def draw_matches(img1, keypoints1, img2, keypoints2, matches):\n",
    "  r, c = img1.shape[:2]\n",
    "  r1, c1 = img2.shape[:2]\n",
    "\n",
    "  # Create a blank image with the size of the first image + second image\n",
    "  output_img = np.zeros((max([r, r1]), c+c1, 3), dtype='uint8')\n",
    "  output_img[:r, :c, :] = np.dstack([img1, img1, img1])\n",
    "  output_img[:r1, c:c+c1, :] = np.dstack([img2, img2, img2])\n",
    "\n",
    "  # Go over all of the matching points and extract them\n",
    "  for match in matches:\n",
    "    img1_idx = match.queryIdx\n",
    "    img2_idx = match.trainIdx\n",
    "    (x1, y1) = keypoints1[img1_idx].pt\n",
    "    (x2, y2) = keypoints2[img2_idx].pt\n",
    "\n",
    "    # Draw circles on the keypoints\n",
    "    cv2.circle(output_img, (int(x1),int(y1)), 4, (0, 255, 255), 1)\n",
    "    cv2.circle(output_img, (int(x2)+c,int(y2)), 4, (0, 255, 255), 1)\n",
    "\n",
    "    # Connect the same keypoints\n",
    "    cv2.line(output_img, (int(x1),int(y1)), (int(x2)+c,int(y2)), (0, 255, 255), 1)\n",
    "\n",
    "  return output_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "all_matches = []\n",
    "for m, n in matches:\n",
    "  all_matches.append(m)\n",
    "\n",
    "img3 = draw_matches(img1, keypoints1, img2, keypoints2, all_matches[:30])\n",
    "# cv2.imshow(\"output\", img3)\n",
    "#\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# Finding the best matches\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.6 * n.distance:\n",
    "        good.append(m)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# cv2.imshow(\"goodKeys1\", cv2.drawKeypoints(img1, [keypoints1[m.queryIdx] for m in good], None, (255, 0, 255)))\n",
    "# cv2.imshow(\"goodKeys2\", cv2.drawKeypoints(img2, [keypoints2[m.trainIdx] for m in good], None, (255, 0, 255)))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def warpImages(img1, img2, H):\n",
    "\n",
    "  rows1, cols1 = img1.shape[:2]\n",
    "  rows2, cols2 = img2.shape[:2]\n",
    "\n",
    "  list_of_points_1 = np.float32([[0,0], [0, rows1],[cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
    "  temp_points = np.float32([[0,0], [0,rows2], [cols2,rows2], [cols2,0]]).reshape(-1,1,2)\n",
    "\n",
    "  # When we have established a homography we need to warp perspective\n",
    "  # Change field of view\n",
    "  list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
    "\n",
    "  list_of_points = np.concatenate((list_of_points_1,list_of_points_2), axis=0)\n",
    "\n",
    "  [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
    "  [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "  translation_dist = [-x_min,-y_min]\n",
    "\n",
    "  H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "\n",
    "  output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
    "  output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
    "\n",
    "  return output_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# Set minimum match condition\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "if len(good) > MIN_MATCH_COUNT:\n",
    "    # Convert keypoints to an argument for findHomography\n",
    "    src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "    # Establish a homography\n",
    "    M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "    result = warpImages(img2, img1, M)\n",
    "    # cv2.imshow(\"result\", result)\n",
    "    #\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def main(img1, img2):\n",
    "    # Create our ORB detector and detect keypoints and descriptors\n",
    "    orb = cv2.ORB_create(nfeatures=2000)\n",
    "\n",
    "    # Find the key points and descriptors with ORB\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "    # Create a BFMatcher object.\n",
    "    # It will find all of the matching keypoints on two images\n",
    "    bf = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
    "\n",
    "    # Find matching points\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2,k=2)\n",
    "\n",
    "    all_matches = []\n",
    "    for m, n in matches:\n",
    "      all_matches.append(m)\n",
    "\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.6 * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    # Set minimum match condition\n",
    "    MIN_MATCH_COUNT = 10\n",
    "\n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        # Convert keypoints to an argument for findHomography\n",
    "        src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "\n",
    "        # Establish a homography\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "        result = warpImages(img2, img1, M)\n",
    "\n",
    "        return result\n",
    "    else:\n",
    "        return img1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "path = \"clear_data/photo\"\n",
    "\n",
    "start = 20\n",
    "first = listdir(path)[start]\n",
    "img1 = cv2.imread(join(path, first), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "for i in range(start + 1, start + 30):\n",
    "    second = listdir(path)[i]\n",
    "    img2 = cv2.imread(join(path, second), cv2.IMREAD_GRAYSCALE)\n",
    "    img1 = main(img1, img2)\n",
    "\n",
    "cv2.imshow(\"res\", img1)\n",
    "cv2.imwrite(\"res.jpg\", img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
